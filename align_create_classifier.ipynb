{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.16.1 in c:\\users\\mypc\\anaconda3\\lib\\site-packages (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16.1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions for building the face recognition network.\n",
    "\"\"\"\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "from tensorflow.python.training import training\n",
    "import random\n",
    "import re\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, alpha):\n",
    "    \"\"\"Calculate the triplet loss according to the FaceNet paper\n",
    "    \n",
    "    Args:\n",
    "      anchor: the embeddings for the anchor images.\n",
    "      positive: the embeddings for the positive images.\n",
    "      negative: the embeddings for the negative images.\n",
    "  \n",
    "    Returns:\n",
    "      the triplet loss according to the FaceNet paper as a float tensor.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('triplet_loss'):\n",
    "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
    "        \n",
    "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
    "      \n",
    "    return loss\n",
    "  \n",
    "def decov_loss(xs):\n",
    "    \"\"\"Decov loss as described in https://arxiv.org/pdf/1511.06068.pdf\n",
    "    'Reducing Overfitting In Deep Networks by Decorrelating Representation'\n",
    "    \"\"\"\n",
    "    x = tf.reshape(xs, [int(xs.get_shape()[0]), -1])\n",
    "    m = tf.reduce_mean(x, 0, True)\n",
    "    z = tf.expand_dims(x-m, 2)\n",
    "    corr = tf.reduce_mean(tf.matmul(z, tf.transpose(z, perm=[0,2,1])), 0)\n",
    "    corr_frob_sqr = tf.reduce_sum(tf.square(corr))\n",
    "    corr_diag_sqr = tf.reduce_sum(tf.square(tf.diag_part(corr)))\n",
    "    loss = 0.5*(corr_frob_sqr - corr_diag_sqr)\n",
    "    return loss \n",
    "  \n",
    "def center_loss(features, label, alfa, nrof_classes):\n",
    "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n",
    "       (http://ydwen.github.io/papers/WenECCV16.pdf)\n",
    "    \"\"\"\n",
    "    nrof_features = features.get_shape()[1]\n",
    "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\n",
    "        initializer=tf.constant_initializer(0), trainable=False)\n",
    "    label = tf.reshape(label, [-1])\n",
    "    centers_batch = tf.gather(centers, label)\n",
    "    diff = (1 - alfa) * (centers_batch - features)\n",
    "    centers = tf.scatter_sub(centers, label, diff)\n",
    "    loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
    "    return loss, centers\n",
    "\n",
    "def get_image_paths_and_labels(dataset):\n",
    "    image_paths_flat = []\n",
    "    labels_flat = []\n",
    "    for i in range(len(dataset)):\n",
    "        image_paths_flat += dataset[i].image_paths\n",
    "        labels_flat += [i] * len(dataset[i].image_paths)\n",
    "    return image_paths_flat, labels_flat\n",
    "\n",
    "def shuffle_examples(image_paths, labels):\n",
    "    shuffle_list = list(zip(image_paths, labels))\n",
    "    random.shuffle(shuffle_list)\n",
    "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n",
    "    return image_paths_shuff, labels_shuff\n",
    "\n",
    "def read_images_from_disk(input_queue):\n",
    "    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n",
    "    Args:\n",
    "      filename_and_label_tensor: A scalar string tensor.\n",
    "    Returns:\n",
    "      Two tensors: the decoded image, and the string label.\n",
    "    \"\"\"\n",
    "    label = input_queue[1]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_png(file_contents, channels=3)\n",
    "    return example, label\n",
    "  \n",
    "def random_rotate_image(image):\n",
    "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
    "    return misc.imrotate(image, angle, 'bicubic')\n",
    "  \n",
    "def read_and_augment_data(image_list, label_list, image_size, batch_size, max_nrof_epochs, \n",
    "        random_crop, random_flip, random_rotate, nrof_preprocess_threads, shuffle=True):\n",
    "    \n",
    "    images = ops.convert_to_tensor(image_list, dtype=tf.string)\n",
    "    labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "    \n",
    "    # Makes an input queue\n",
    "    input_queue = tf.train.slice_input_producer([images, labels],\n",
    "        num_epochs=max_nrof_epochs, shuffle=shuffle)\n",
    "\n",
    "    images_and_labels = []\n",
    "    for _ in range(nrof_preprocess_threads):\n",
    "        image, label = read_images_from_disk(input_queue)\n",
    "        if random_rotate:\n",
    "            image = tf.py_func(random_rotate_image, [image], tf.uint8)\n",
    "        if random_crop:\n",
    "            image = tf.random_crop(image, [image_size, image_size, 3])\n",
    "        else:\n",
    "            image = tf.image.resize_image_with_crop_or_pad(image, image_size, image_size)\n",
    "        if random_flip:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "        #pylint: disable=no-member\n",
    "        image.set_shape((image_size, image_size, 3))\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        images_and_labels.append([image, label])\n",
    "\n",
    "    image_batch, label_batch = tf.train.batch_join(\n",
    "        images_and_labels, batch_size=batch_size,\n",
    "        capacity=4 * nrof_preprocess_threads * batch_size,\n",
    "        allow_smaller_final_batch=True)\n",
    "  \n",
    "    return image_batch, label_batch\n",
    "  \n",
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses.\n",
    "  \n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "  \n",
    "    Args:\n",
    "      total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "      loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "  \n",
    "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name +'(raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "  \n",
    "    return loss_averages_op\n",
    "\n",
    "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n",
    "    # Generate moving averages of all losses and associated summaries.\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        if optimizer=='ADAGRAD':\n",
    "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
    "        elif optimizer=='ADADELTA':\n",
    "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
    "        elif optimizer=='ADAM':\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
    "        elif optimizer=='RMSPROP':\n",
    "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
    "        elif optimizer=='MOM':\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "        else:\n",
    "            raise ValueError('Invalid optimization algorithm')\n",
    "    \n",
    "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
    "        \n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "  \n",
    "    # Add histograms for trainable variables.\n",
    "    if log_histograms:\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.summary.histogram(var.op.name, var)\n",
    "   \n",
    "    # Add histograms for gradients.\n",
    "    if log_histograms:\n",
    "        for grad, var in grads:\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "  \n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        moving_average_decay, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "  \n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "  \n",
    "    return train_op\n",
    "\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y  \n",
    "\n",
    "def crop(image, random_crop, image_size):\n",
    "    if image.shape[1]>image_size:\n",
    "        sz1 = int(image.shape[1]//2)\n",
    "        sz2 = int(image_size//2)\n",
    "        if random_crop:\n",
    "            diff = sz1-sz2\n",
    "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
    "        else:\n",
    "            (h, v) = (0,0)\n",
    "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
    "    return image\n",
    "  \n",
    "def flip(image, random_flip):\n",
    "    if random_flip and np.random.choice([True, False]):\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "def to_rgb(img):\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
    "    return ret\n",
    "  \n",
    "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
    "    nrof_samples = len(image_paths)\n",
    "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
    "    for i in range(nrof_samples):\n",
    "        img = misc.imread(image_paths[i])\n",
    "        if img.ndim == 2:\n",
    "            img = to_rgb(img)\n",
    "        if do_prewhiten:\n",
    "            img = prewhiten(img)\n",
    "        img = crop(img, do_random_crop, image_size)\n",
    "        img = flip(img, do_random_flip)\n",
    "        images[i,:,:,:] = img\n",
    "    return images\n",
    "\n",
    "def get_label_batch(label_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(label_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = label_data[j:j+batch_size]\n",
    "    else:\n",
    "        x1 = label_data[j:nrof_examples]\n",
    "        x2 = label_data[0:nrof_examples-j]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_int = batch.astype(np.int64)\n",
    "    return batch_int\n",
    "\n",
    "def get_batch(image_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(image_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = image_data[j:j+batch_size,:,:,:]\n",
    "    else:\n",
    "        x1 = image_data[j:nrof_examples,:,:,:]\n",
    "        x2 = image_data[0:nrof_examples-j,:,:,:]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_float = batch.astype(np.float32)\n",
    "    return batch_float\n",
    "\n",
    "def get_triplet_batch(triplets, batch_index, batch_size):\n",
    "    ax, px, nx = triplets\n",
    "    a = get_batch(ax, int(batch_size/3), batch_index)\n",
    "    p = get_batch(px, int(batch_size/3), batch_index)\n",
    "    n = get_batch(nx, int(batch_size/3), batch_index)\n",
    "    batch = np.vstack([a, p, n])\n",
    "    return batch\n",
    "\n",
    "def get_learning_rate_from_file(filename, epoch):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split('#', 1)[0]\n",
    "            if line:\n",
    "                par = line.strip().split(':')\n",
    "                e = int(par[0])\n",
    "                lr = float(par[1])\n",
    "                if e <= epoch:\n",
    "                    learning_rate = lr\n",
    "                else:\n",
    "                    return learning_rate\n",
    "\n",
    "class ImageClass():\n",
    "    \"Stores the paths to images for a given class\"\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "  \n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "def get_dataset(paths, has_class_directories=True):\n",
    "    dataset = []\n",
    "    for path in paths.split(':'):\n",
    "        path_exp = os.path.expanduser(path)\n",
    "        classes = os.listdir(path_exp)\n",
    "        classes.sort()\n",
    "        nrof_classes = len(classes)\n",
    "        for i in range(nrof_classes):\n",
    "            class_name = classes[i]\n",
    "            facedir = os.path.join(path_exp, class_name)\n",
    "            image_paths = get_image_paths(facedir)\n",
    "            dataset.append(ImageClass(class_name, image_paths))\n",
    "  \n",
    "    return dataset\n",
    "\n",
    "def get_image_paths(facedir):\n",
    "    image_paths = []\n",
    "    if os.path.isdir(facedir):\n",
    "        images = os.listdir(facedir)\n",
    "        image_paths = [os.path.join(facedir,img) for img in images]\n",
    "    return image_paths\n",
    "  \n",
    "def split_dataset(dataset, split_ratio, mode):\n",
    "    if mode=='SPLIT_CLASSES':\n",
    "        nrof_classes = len(dataset)\n",
    "        class_indices = np.arange(nrof_classes)\n",
    "        np.random.shuffle(class_indices)\n",
    "        split = int(round(nrof_classes*split_ratio))\n",
    "        train_set = [dataset[i] for i in class_indices[0:split]]\n",
    "        test_set = [dataset[i] for i in class_indices[split:-1]]\n",
    "    elif mode=='SPLIT_IMAGES':\n",
    "        train_set = []\n",
    "        test_set = []\n",
    "        min_nrof_images = 2\n",
    "        for cls in dataset:\n",
    "            paths = cls.image_paths\n",
    "            np.random.shuffle(paths)\n",
    "            split = int(round(len(paths)*split_ratio))\n",
    "            if split<min_nrof_images:\n",
    "                continue  # Not enough images for test set. Skip class...\n",
    "            train_set.append(ImageClass(cls.name, paths[0:split]))\n",
    "            test_set.append(ImageClass(cls.name, paths[split:-1]))\n",
    "    else:\n",
    "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\n",
    "    return train_set, test_set\n",
    "\n",
    "def load_model(model):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "    \n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    \n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff),1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        \n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "          \n",
    "        tpr = np.mean(tprs,0)\n",
    "        fpr = np.mean(fprs,0)\n",
    "    return tpr, fpr, accuracy\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "  \n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc\n",
    "\n",
    "\n",
    "  \n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "    \n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff),1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "      \n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train)>=far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "    \n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "  \n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "\n",
    "def store_revision_info(src_path, output_dir, arg_string):\n",
    "  \n",
    "    # Get git hash\n",
    "    gitproc = Popen(['git', 'rev-parse', 'HEAD'], stdout = PIPE, cwd=src_path)\n",
    "    (stdout, _) = gitproc.communicate()\n",
    "    git_hash = stdout.strip()\n",
    "  \n",
    "    # Get local changes\n",
    "    gitproc = Popen(['git', 'diff', 'HEAD'], stdout = PIPE, cwd=src_path)\n",
    "    (stdout, _) = gitproc.communicate()\n",
    "    git_diff = stdout.strip()\n",
    "    \n",
    "    # Store a text file in the log directory\n",
    "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\n",
    "    with open(rev_info_filename, \"w\") as text_file:\n",
    "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\n",
    "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\n",
    "        text_file.write('%s' % git_diff)\n",
    "\n",
    "def list_variables(filename):\n",
    "    reader = training.NewCheckpointReader(filename)\n",
    "    variable_map = reader.get_variable_to_shape_map()\n",
    "    names = sorted(variable_map.keys())\n",
    "    return names\n",
    "\n",
    "def put_images_on_grid(images, shape=(16,8)):\n",
    "    nrof_images = images.shape[0]\n",
    "    img_size = images.shape[1]\n",
    "    bw = 3\n",
    "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n",
    "    for i in range(shape[1]):\n",
    "        x_start = i*(img_size+bw)+bw\n",
    "        for j in range(shape[0]):\n",
    "            img_index = i*shape[0]+j\n",
    "            if img_index>=nrof_images:\n",
    "                break\n",
    "            y_start = j*(img_size+bw)+bw\n",
    "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n",
    "        if img_index>=nrof_images:\n",
    "            break\n",
    "    return img\n",
    "\n",
    "def write_arguments_to_file(args, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for key, value in vars(args).iteritems():\n",
    "            f.write('%s: %s\\n' % (key, str(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Tensorflow implementation of the face detection / alignment algorithm found at\n",
    "https://github.com/kpzhang93/MTCNN_face_detection_alignment\n",
    "\"\"\"\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six import string_types, iteritems\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from math import floor\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def layer(op):\n",
    "    '''Decorator for composable network layers.'''\n",
    "\n",
    "    def layer_decorated(self, *args, **kwargs):\n",
    "        # Automatically set a name if not provided.\n",
    "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n",
    "        # Figure out the layer inputs.\n",
    "        if len(self.terminals) == 0:\n",
    "            raise RuntimeError('No input variables found for layer %s.' % name)\n",
    "        elif len(self.terminals) == 1:\n",
    "            layer_input = self.terminals[0]\n",
    "        else:\n",
    "            layer_input = list(self.terminals)\n",
    "        # Perform the operation and get the output.\n",
    "        layer_output = op(self, layer_input, *args, **kwargs)\n",
    "        # Add to layer LUT.\n",
    "        self.layers[name] = layer_output\n",
    "        # This output is now the input for the next layer.\n",
    "        self.feed(layer_output)\n",
    "        # Return self for chained calls.\n",
    "        return self\n",
    "\n",
    "    return layer_decorated\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, inputs, trainable=True):\n",
    "        # The input nodes for this network\n",
    "        self.inputs = inputs\n",
    "        # The current list of terminal nodes\n",
    "        self.terminals = []\n",
    "        # Mapping from layer names to layers\n",
    "        self.layers = dict(inputs)\n",
    "        # If true, the resulting variables are set as trainable\n",
    "        self.trainable = trainable\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        '''Construct the network. '''\n",
    "        raise NotImplementedError('Must be implemented by the subclass.')\n",
    "\n",
    "    def load(self, data_path, session, ignore_missing=False):\n",
    "        '''Load network weights.\n",
    "        data_path: The path to the numpy-serialized network weights\n",
    "        session: The current TensorFlow session\n",
    "        ignore_missing: If true, serialized weights for missing layers are ignored.\n",
    "        '''\n",
    "        data_dict = np.load(data_path, encoding='latin1').item() #pylint: disable=no-member\n",
    "\n",
    "        for op_name in data_dict:\n",
    "            with tf.variable_scope(op_name, reuse=True):\n",
    "                for param_name, data in iteritems(data_dict[op_name]):\n",
    "                    try:\n",
    "                        var = tf.get_variable(param_name)\n",
    "                        session.run(var.assign(data))\n",
    "                    except ValueError:\n",
    "                        if not ignore_missing:\n",
    "                            raise\n",
    "\n",
    "    def feed(self, *args):\n",
    "        '''Set the input(s) for the next operation by replacing the terminal nodes.\n",
    "        The arguments can be either layer names or the actual layers.\n",
    "        '''\n",
    "        assert len(args) != 0\n",
    "        self.terminals = []\n",
    "        for fed_layer in args:\n",
    "            if isinstance(fed_layer, string_types):\n",
    "                try:\n",
    "                    fed_layer = self.layers[fed_layer]\n",
    "                except KeyError:\n",
    "                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n",
    "            self.terminals.append(fed_layer)\n",
    "        return self\n",
    "\n",
    "    def get_output(self):\n",
    "        '''Returns the current network output.'''\n",
    "        return self.terminals[-1]\n",
    "\n",
    "    def get_unique_name(self, prefix):\n",
    "        '''Returns an index-suffixed unique name for the given prefix.\n",
    "        This is used for auto-generating layer names based on the type-prefix.\n",
    "        '''\n",
    "        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n",
    "        return '%s_%d' % (prefix, ident)\n",
    "\n",
    "    def make_var(self, name, shape):\n",
    "        '''Creates a new TensorFlow variable.'''\n",
    "        return tf.get_variable(name, shape, trainable=self.trainable)\n",
    "\n",
    "    def validate_padding(self, padding):\n",
    "        '''Verifies that the padding is one of the supported ones.'''\n",
    "        assert padding in ('SAME', 'VALID')\n",
    "\n",
    "    @layer\n",
    "    def conv(self,\n",
    "             inp,\n",
    "             k_h,\n",
    "             k_w,\n",
    "             c_o,\n",
    "             s_h,\n",
    "             s_w,\n",
    "             name,\n",
    "             relu=True,\n",
    "             padding='SAME',\n",
    "             group=1,\n",
    "             biased=True):\n",
    "        # Verify that the padding is acceptable\n",
    "        self.validate_padding(padding)\n",
    "        # Get the number of channels in the input\n",
    "        c_i = int(inp.get_shape()[-1])\n",
    "        # Verify that the grouping parameter is valid\n",
    "        assert c_i % group == 0\n",
    "        assert c_o % group == 0\n",
    "        # Convolution for a given input and kernel\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            kernel = self.make_var('weights', shape=[k_h, k_w, c_i // group, c_o])\n",
    "            # This is the common-case. Convolve the input without any further complications.\n",
    "            output = convolve(inp, kernel)\n",
    "            # Add the biases\n",
    "            if biased:\n",
    "                biases = self.make_var('biases', [c_o])\n",
    "                output = tf.nn.bias_add(output, biases)\n",
    "            if relu:\n",
    "                # ReLU non-linearity\n",
    "                output = tf.nn.relu(output, name=scope.name)\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def prelu(self, inp, name):\n",
    "        with tf.variable_scope(name):\n",
    "            i = int(inp.get_shape()[-1])\n",
    "            alpha = self.make_var('alpha', shape=(i,))\n",
    "            output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n",
    "        return output\n",
    "\n",
    "    @layer\n",
    "    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.max_pool(inp,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def fc(self, inp, num_out, name, relu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            input_shape = inp.get_shape()\n",
    "            if input_shape.ndims == 4:\n",
    "                # The input is spatial. Vectorize it first.\n",
    "                dim = 1\n",
    "                for d in input_shape[1:].as_list():\n",
    "                    dim *= int(d)\n",
    "                feed_in = tf.reshape(inp, [-1, dim])\n",
    "            else:\n",
    "                feed_in, dim = (inp, input_shape[-1].value)\n",
    "            weights = self.make_var('weights', shape=[dim, num_out])\n",
    "            biases = self.make_var('biases', [num_out])\n",
    "            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n",
    "            fc = op(feed_in, weights, biases, name=name)\n",
    "            return fc\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Multi dimensional softmax,\n",
    "    refer to https://github.com/tensorflow/tensorflow/issues/210\n",
    "    compute softmax along the dimension of target\n",
    "    the native softmax only supports batch_size x dimension\n",
    "    \"\"\"\n",
    "    @layer\n",
    "    def softmax(self, target, axis, name=None):\n",
    "        max_axis = tf.reduce_max(target, axis, keep_dims=True)\n",
    "        target_exp = tf.exp(target-max_axis)\n",
    "        normalize = tf.reduce_sum(target_exp, axis, keep_dims=True)\n",
    "        softmax = tf.div(target_exp, normalize, name)\n",
    "        return softmax\n",
    "    \n",
    "class PNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='PReLU1')\n",
    "             .max_pool(2, 2, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='PReLU2')\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='PReLU3')\n",
    "             .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1')\n",
    "             .softmax(3,name='prob1'))\n",
    "\n",
    "        (self.feed('PReLU3') #pylint: disable=no-value-for-parameter\n",
    "             .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))\n",
    "        \n",
    "class RNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 28, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 48, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(2, 2, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .fc(128, relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(2, relu=False, name='conv5-1')\n",
    "             .softmax(1,name='prob1'))\n",
    "\n",
    "        (self.feed('prelu4') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv5-2'))\n",
    "\n",
    "class ONet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .max_pool(2, 2, 2, 2, name='pool3')\n",
    "             .conv(2, 2, 128, 1, 1, padding='VALID', relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(256, relu=False, name='conv5')\n",
    "             .prelu(name='prelu5')\n",
    "             .fc(2, relu=False, name='conv6-1')\n",
    "             .softmax(1, name='prob1'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv6-2'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(10, relu=False, name='conv6-3'))\n",
    "\n",
    "def create_mtcnn(sess, model_path):\n",
    "    if not model_path:\n",
    "        model_path,_ = os.path.split(os.path.realpath(__file__))\n",
    "\n",
    "    with tf.variable_scope('pnet'):\n",
    "        data = tf.placeholder(tf.float32, (None,None,None,3), 'input')\n",
    "        pnet = PNet({'data':data})\n",
    "        pnet.load(os.path.join(model_path, 'det1.npy'), sess)\n",
    "    with tf.variable_scope('rnet'):\n",
    "        data = tf.placeholder(tf.float32, (None,24,24,3), 'input')\n",
    "        rnet = RNet({'data':data})\n",
    "        rnet.load(os.path.join(model_path, 'det2.npy'), sess)\n",
    "    with tf.variable_scope('onet'):\n",
    "        data = tf.placeholder(tf.float32, (None,48,48,3), 'input')\n",
    "        onet = ONet({'data':data})\n",
    "        onet.load(os.path.join(model_path, 'det3.npy'), sess)\n",
    "        \n",
    "    pnet_fun = lambda img : sess.run(('pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'), feed_dict={'pnet/input:0':img})\n",
    "    rnet_fun = lambda img : sess.run(('rnet/conv5-2/conv5-2:0', 'rnet/prob1:0'), feed_dict={'rnet/input:0':img})\n",
    "    onet_fun = lambda img : sess.run(('onet/conv6-2/conv6-2:0', 'onet/conv6-3/conv6-3:0', 'onet/prob1:0'), feed_dict={'onet/input:0':img})\n",
    "    return pnet_fun, rnet_fun, onet_fun\n",
    "\n",
    "def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n",
    "    # im: input image\n",
    "    # minsize: minimum of faces' size\n",
    "    # pnet, rnet, onet: caffemodel\n",
    "    # threshold: threshold=[th1 th2 th3], th1-3 are three steps's threshold\n",
    "    # fastresize: resize img from last scale (using in high-resolution images) if fastresize==true\n",
    "    factor_count=0\n",
    "    total_boxes=np.empty((0,9))\n",
    "    points=np.empty(0)\n",
    "    h=img.shape[0]\n",
    "    w=img.shape[1]\n",
    "    minl=np.amin([h, w])\n",
    "    m=15.0/minsize\n",
    "    minl=minl*m\n",
    "    # creat scale pyramid\n",
    "    scales=[]\n",
    "    while minl>=12:\n",
    "        scales += [m*np.power(factor, factor_count)]\n",
    "        minl = minl*factor\n",
    "        factor_count += 1\n",
    "\n",
    "    # first stage\n",
    "    for j in range(len(scales)):\n",
    "        scale=scales[j]\n",
    "        hs=int(np.ceil(h*scale))\n",
    "        ws=int(np.ceil(w*scale))\n",
    "        im_data = imresample(img, (hs, ws))\n",
    "        im_data = (im_data-127.5)*0.0078125\n",
    "        img_x = np.expand_dims(im_data, 0)\n",
    "        img_y = np.transpose(img_x, (0,2,1,3))\n",
    "        out = pnet(img_y)\n",
    "        out0 = np.transpose(out[0], (0,2,1,3))\n",
    "        out1 = np.transpose(out[1], (0,2,1,3))\n",
    "        \n",
    "        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n",
    "        \n",
    "        # inter-scale nms\n",
    "        pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "        if boxes.size>0 and pick.size>0:\n",
    "            boxes = boxes[pick,:]\n",
    "            total_boxes = np.append(total_boxes, boxes, axis=0)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        pick = nms(total_boxes.copy(), 0.7, 'Union')\n",
    "        total_boxes = total_boxes[pick,:]\n",
    "        regw = total_boxes[:,2]-total_boxes[:,0]\n",
    "        regh = total_boxes[:,3]-total_boxes[:,1]\n",
    "        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n",
    "        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n",
    "        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n",
    "        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n",
    "        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n",
    "        total_boxes = rerec(total_boxes.copy())\n",
    "        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # second stage\n",
    "        tempimg = np.zeros((24,24,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = rnet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        score = out1[1,:]\n",
    "        ipass = np.where(score>threshold[1])\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "        if total_boxes.shape[0]>0:\n",
    "            pick = nms(total_boxes, 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n",
    "            total_boxes = rerec(total_boxes.copy())\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # third stage\n",
    "        total_boxes = np.fix(total_boxes).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "        tempimg = np.zeros((48,48,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = onet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        out2 = np.transpose(out[2])\n",
    "        score = out2[1,:]\n",
    "        points = out1\n",
    "        ipass = np.where(score>threshold[2])\n",
    "        points = points[:,ipass[0]]\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "\n",
    "        w = total_boxes[:,2]-total_boxes[:,0]+1\n",
    "        h = total_boxes[:,3]-total_boxes[:,1]+1\n",
    "        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n",
    "        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n",
    "        if total_boxes.shape[0]>0:\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n",
    "            pick = nms(total_boxes.copy(), 0.7, 'Min')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            points = points[:,pick]\n",
    "                \n",
    "    return total_boxes, points\n",
    "\n",
    "\n",
    "def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, threshold, factor):\n",
    "    # im: input image\n",
    "    # minsize: minimum of faces' size\n",
    "    # pnet, rnet, onet: caffemodel\n",
    "    # threshold: threshold=[th1 th2 th3], th1-3 are three steps's threshold [0-1]\n",
    "\n",
    "    all_scales = [None] * len(images)\n",
    "    images_with_boxes = [None] * len(images)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images_with_boxes[i] = {'total_boxes': np.empty((0, 9))}\n",
    "\n",
    "    # create scale pyramid\n",
    "    for index, img in enumerate(images):\n",
    "        all_scales[index] = []\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "        minsize = int(detection_window_size_ratio * np.minimum(w, h))\n",
    "        factor_count = 0\n",
    "        minl = np.amin([h, w])\n",
    "        if minsize <= 12:\n",
    "            minsize = 12\n",
    "\n",
    "        m = 12.0 / minsize\n",
    "        minl = minl * m\n",
    "        while minl >= 12:\n",
    "            all_scales[index].append(m * np.power(factor, factor_count))\n",
    "            minl = minl * factor\n",
    "            factor_count += 1\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # first stage - fast proposal network (pnet) to obtain face candidates\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    images_obj_per_resolution = {}\n",
    "\n",
    "    # TODO: use some type of rounding to number module 8 to increase probability that pyramid images will have the same resolution across input images\n",
    "\n",
    "    for index, scales in enumerate(all_scales):\n",
    "        h = images[index].shape[0]\n",
    "        w = images[index].shape[1]\n",
    "\n",
    "        for scale in scales:\n",
    "            hs = int(np.ceil(h * scale))\n",
    "            ws = int(np.ceil(w * scale))\n",
    "\n",
    "            if (ws, hs) not in images_obj_per_resolution:\n",
    "                images_obj_per_resolution[(ws, hs)] = []\n",
    "\n",
    "            im_data = imresample(images[index], (hs, ws))\n",
    "            im_data = (im_data - 127.5) * 0.0078125\n",
    "            img_y = np.transpose(im_data, (1, 0, 2))  # caffe uses different dimensions ordering\n",
    "            images_obj_per_resolution[(ws, hs)].append({'scale': scale, 'image': img_y, 'index': index})\n",
    "\n",
    "    for resolution in images_obj_per_resolution:\n",
    "        images_per_resolution = [i['image'] for i in images_obj_per_resolution[resolution]]\n",
    "        outs = pnet(images_per_resolution)\n",
    "\n",
    "        for index in range(len(outs[0])):\n",
    "            scale = images_obj_per_resolution[resolution][index]['scale']\n",
    "            image_index = images_obj_per_resolution[resolution][index]['index']\n",
    "            out0 = np.transpose(outs[0][index], (1, 0, 2))\n",
    "            out1 = np.transpose(outs[1][index], (1, 0, 2))\n",
    "\n",
    "            boxes, _ = generateBoundingBox(out1[:, :, 1].copy(), out0[:, :, :].copy(), scale, threshold[0])\n",
    "\n",
    "            # inter-scale nms\n",
    "            pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "            if boxes.size > 0 and pick.size > 0:\n",
    "                boxes = boxes[pick, :]\n",
    "                images_with_boxes[image_index]['total_boxes'] = np.append(images_with_boxes[image_index]['total_boxes'],\n",
    "                                                                          boxes,\n",
    "                                                                          axis=0)\n",
    "\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        numbox = image_obj['total_boxes'].shape[0]\n",
    "        if numbox > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            regw = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0]\n",
    "            regh = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1]\n",
    "            qq1 = image_obj['total_boxes'][:, 0] + image_obj['total_boxes'][:, 5] * regw\n",
    "            qq2 = image_obj['total_boxes'][:, 1] + image_obj['total_boxes'][:, 6] * regh\n",
    "            qq3 = image_obj['total_boxes'][:, 2] + image_obj['total_boxes'][:, 7] * regw\n",
    "            qq4 = image_obj['total_boxes'][:, 3] + image_obj['total_boxes'][:, 8] * regh\n",
    "            image_obj['total_boxes'] = np.transpose(np.vstack([qq1, qq2, qq3, qq4, image_obj['total_boxes'][:, 4]]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "            image_obj['total_boxes'][:, 0:4] = np.fix(image_obj['total_boxes'][:, 0:4]).astype(np.int32)\n",
    "            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "            tempimg = np.zeros((24, 24, 3, numbox))\n",
    "\n",
    "            if numbox > 0:\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['rnet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # second stage - refinement of face candidates with rnet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_rnet_input = np.empty((0, 24, 24, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' in image_obj:\n",
    "            bulk_rnet_input = np.append(bulk_rnet_input, image_obj['rnet_input'], axis=0)\n",
    "\n",
    "    out = rnet(bulk_rnet_input)\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    score = out1[1, :]\n",
    "\n",
    "    i = 0\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' not in image_obj:\n",
    "            continue\n",
    "\n",
    "        rnet_input_count = image_obj['rnet_input'].shape[0]\n",
    "        score_per_image = score[i:i + rnet_input_count]\n",
    "        out0_per_image = out0[:, i:i + rnet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[1])\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'], 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv[:, pick]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "\n",
    "            if numbox > 0:\n",
    "                tempimg = np.zeros((48, 48, 3, numbox))\n",
    "                image_obj['total_boxes'] = np.fix(image_obj['total_boxes']).astype(np.int32)\n",
    "                dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['onet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "        i += rnet_input_count\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # third stage - further refinement and facial landmarks positions with onet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_onet_input = np.empty((0, 48, 48, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' in image_obj:\n",
    "            bulk_onet_input = np.append(bulk_onet_input, image_obj['onet_input'], axis=0)\n",
    "\n",
    "    out = onet(bulk_onet_input)\n",
    "\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    out2 = np.transpose(out[2])\n",
    "    score = out2[1, :]\n",
    "    points = out1\n",
    "\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' not in image_obj:\n",
    "            ret.append(None)\n",
    "            continue\n",
    "\n",
    "        onet_input_count = image_obj['onet_input'].shape[0]\n",
    "\n",
    "        out0_per_image = out0[:, i:i + onet_input_count]\n",
    "        score_per_image = score[i:i + onet_input_count]\n",
    "        points_per_image = points[:, i:i + onet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[2])\n",
    "        points_per_image = points_per_image[:, ipass[0]]\n",
    "\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        w = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0] + 1\n",
    "        h = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1] + 1\n",
    "        points_per_image[0:5, :] = np.tile(w, (5, 1)) * points_per_image[0:5, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 0], (5, 1)) - 1\n",
    "        points_per_image[5:10, :] = np.tile(h, (5, 1)) * points_per_image[5:10, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 1], (5, 1)) - 1\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv))\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Min')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            points_per_image = points_per_image[:, pick]\n",
    "\n",
    "            ret.append((image_obj['total_boxes'], points_per_image))\n",
    "        else:\n",
    "            ret.append(None)\n",
    "\n",
    "        i += onet_input_count\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "# function [boundingbox] = bbreg(boundingbox,reg)\n",
    "def bbreg(boundingbox,reg):\n",
    "    # calibrate bounding boxes\n",
    "    if reg.shape[1]==1:\n",
    "        reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n",
    "\n",
    "    w = boundingbox[:,2]-boundingbox[:,0]+1\n",
    "    h = boundingbox[:,3]-boundingbox[:,1]+1\n",
    "    b1 = boundingbox[:,0]+reg[:,0]*w\n",
    "    b2 = boundingbox[:,1]+reg[:,1]*h\n",
    "    b3 = boundingbox[:,2]+reg[:,2]*w\n",
    "    b4 = boundingbox[:,3]+reg[:,3]*h\n",
    "    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n",
    "    return boundingbox\n",
    " \n",
    "def generateBoundingBox(imap, reg, scale, t):\n",
    "    # use heatmap to generate bounding boxes\n",
    "    stride=2\n",
    "    cellsize=12\n",
    "\n",
    "    imap = np.transpose(imap)\n",
    "    dx1 = np.transpose(reg[:,:,0])\n",
    "    dy1 = np.transpose(reg[:,:,1])\n",
    "    dx2 = np.transpose(reg[:,:,2])\n",
    "    dy2 = np.transpose(reg[:,:,3])\n",
    "    y, x = np.where(imap >= t)\n",
    "    if y.shape[0]==1:\n",
    "        dx1 = np.flipud(dx1)\n",
    "        dy1 = np.flipud(dy1)\n",
    "        dx2 = np.flipud(dx2)\n",
    "        dy2 = np.flipud(dy2)\n",
    "    score = imap[(y,x)]\n",
    "    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n",
    "    if reg.size==0:\n",
    "        reg = np.empty((0,3))\n",
    "    bb = np.transpose(np.vstack([y,x]))\n",
    "    q1 = np.fix((stride*bb+1)/scale)\n",
    "    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n",
    "    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n",
    "    return boundingbox, reg\n",
    " \n",
    "# function pick = nms(boxes,threshold,type)\n",
    "def nms(boxes, threshold, method):\n",
    "    if boxes.size==0:\n",
    "        return np.empty((0,3))\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    area = (x2-x1+1) * (y2-y1+1)\n",
    "    I = np.argsort(s)\n",
    "    pick = np.zeros_like(s, dtype=np.int16)\n",
    "    counter = 0\n",
    "    while I.size>0:\n",
    "        i = I[-1]\n",
    "        pick[counter] = i\n",
    "        counter += 1\n",
    "        idx = I[0:-1]\n",
    "        xx1 = np.maximum(x1[i], x1[idx])\n",
    "        yy1 = np.maximum(y1[i], y1[idx])\n",
    "        xx2 = np.minimum(x2[i], x2[idx])\n",
    "        yy2 = np.minimum(y2[i], y2[idx])\n",
    "        w = np.maximum(0.0, xx2-xx1+1)\n",
    "        h = np.maximum(0.0, yy2-yy1+1)\n",
    "        inter = w * h\n",
    "        if method is 'Min':\n",
    "            o = inter / np.minimum(area[i], area[idx])\n",
    "        else:\n",
    "            o = inter / (area[i] + area[idx] - inter)\n",
    "        I = I[np.where(o<=threshold)]\n",
    "    pick = pick[0:counter]\n",
    "    return pick\n",
    "\n",
    "# function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n",
    "def pad(total_boxes, w, h):\n",
    "    # compute the padding coordinates (pad the bounding boxes to square)\n",
    "    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n",
    "    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n",
    "    numbox = total_boxes.shape[0]\n",
    "\n",
    "    dx = np.ones((numbox), dtype=np.int32)\n",
    "    dy = np.ones((numbox), dtype=np.int32)\n",
    "    edx = tmpw.copy().astype(np.int32)\n",
    "    edy = tmph.copy().astype(np.int32)\n",
    "\n",
    "    x = total_boxes[:,0].copy().astype(np.int32)\n",
    "    y = total_boxes[:,1].copy().astype(np.int32)\n",
    "    ex = total_boxes[:,2].copy().astype(np.int32)\n",
    "    ey = total_boxes[:,3].copy().astype(np.int32)\n",
    "\n",
    "    tmp = np.where(ex>w)\n",
    "    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n",
    "    ex[tmp] = w\n",
    "    \n",
    "    tmp = np.where(ey>h)\n",
    "    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n",
    "    ey[tmp] = h\n",
    "\n",
    "    tmp = np.where(x<1)\n",
    "    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n",
    "    x[tmp] = 1\n",
    "\n",
    "    tmp = np.where(y<1)\n",
    "    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n",
    "    y[tmp] = 1\n",
    "    \n",
    "    return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n",
    "\n",
    "# function [bboxA] = rerec(bboxA)\n",
    "def rerec(bboxA):\n",
    "    # convert bboxA to square\n",
    "    h = bboxA[:,3]-bboxA[:,1]\n",
    "    w = bboxA[:,2]-bboxA[:,0]\n",
    "    l = np.maximum(w, h)\n",
    "    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n",
    "    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n",
    "    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n",
    "    return bboxA\n",
    "\n",
    "def imresample(img, sz):\n",
    "    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n",
    "    return im_data\n",
    "\n",
    "    # This method is kept for debugging purpose\n",
    "#     h=img.shape[0]\n",
    "#     w=img.shape[1]\n",
    "#     hs, ws = sz\n",
    "#     dx = float(w) / ws\n",
    "#     dy = float(h) / hs\n",
    "#     im_data = np.zeros((hs,ws,3))\n",
    "#     for a1 in range(0,hs):\n",
    "#         for a2 in range(0,ws):\n",
    "#             for a3 in range(0,3):\n",
    "#                 im_data[a1,a2,a3] = img[int(floor(a1*dy)),int(floor(a2*dx)),a3]\n",
    "#     return im_datavvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 19:38:06.812819 29284 deprecation.py:506] From C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 19:38:07.071994 29284 deprecation.py:506] From <ipython-input-4-c3ae3176e283>:210: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0911 19:38:07.082423 29284 deprecation.py:506] From <ipython-input-4-c3ae3176e283>:212: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0911 19:38:07.087087 29284 deprecation.py:323] From <ipython-input-4-c3ae3176e283>:213: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodluck\n",
      "aligned_images\\.ipynb_checkpoints\n",
      "aligned_images\\detect_face.cpython-35.pyc\n",
      "aligned_images\\facenet.cpython-35.pyc\n",
      "aligned_images\\harshil\n",
      "images\\harshil\\id.17.0.jpg\n",
      "images\\harshil\\id.17.1.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.1.jpg\"\n",
      "images\\harshil\\id.17.10.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.10.jpg\"\n",
      "images\\harshil\\id.17.100.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.100.jpg\"\n",
      "images\\harshil\\id.17.101.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.101.jpg\"\n",
      "images\\harshil\\id.17.102.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.102.jpg\"\n",
      "images\\harshil\\id.17.103.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.103.jpg\"\n",
      "images\\harshil\\id.17.104.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.104.jpg\"\n",
      "images\\harshil\\id.17.105.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.105.jpg\"\n",
      "images\\harshil\\id.17.106.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.106.jpg\"\n",
      "images\\harshil\\id.17.11.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.11.jpg\"\n",
      "images\\harshil\\id.17.12.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.12.jpg\"\n",
      "images\\harshil\\id.17.13.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.13.jpg\"\n",
      "images\\harshil\\id.17.14.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.14.jpg\"\n",
      "images\\harshil\\id.17.15.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.15.jpg\"\n",
      "images\\harshil\\id.17.16.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.16.jpg\"\n",
      "images\\harshil\\id.17.17.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.17.jpg\"\n",
      "images\\harshil\\id.17.18.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.18.jpg\"\n",
      "images\\harshil\\id.17.19.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.19.jpg\"\n",
      "images\\harshil\\id.17.2.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.2.jpg\"\n",
      "images\\harshil\\id.17.20.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.20.jpg\"\n",
      "images\\harshil\\id.17.21.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.21.jpg\"\n",
      "images\\harshil\\id.17.22.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.22.jpg\"\n",
      "images\\harshil\\id.17.23.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.23.jpg\"\n",
      "images\\harshil\\id.17.24.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.24.jpg\"\n",
      "images\\harshil\\id.17.25.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.25.jpg\"\n",
      "images\\harshil\\id.17.26.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.26.jpg\"\n",
      "images\\harshil\\id.17.27.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.27.jpg\"\n",
      "images\\harshil\\id.17.28.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.28.jpg\"\n",
      "images\\harshil\\id.17.29.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.29.jpg\"\n",
      "images\\harshil\\id.17.3.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.3.jpg\"\n",
      "images\\harshil\\id.17.30.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.30.jpg\"\n",
      "images\\harshil\\id.17.31.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.31.jpg\"\n",
      "images\\harshil\\id.17.32.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.32.jpg\"\n",
      "images\\harshil\\id.17.33.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.33.jpg\"\n",
      "images\\harshil\\id.17.34.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.34.jpg\"\n",
      "images\\harshil\\id.17.35.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.35.jpg\"\n",
      "images\\harshil\\id.17.36.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.36.jpg\"\n",
      "images\\harshil\\id.17.37.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.37.jpg\"\n",
      "images\\harshil\\id.17.38.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.38.jpg\"\n",
      "images\\harshil\\id.17.39.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.39.jpg\"\n",
      "images\\harshil\\id.17.4.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.4.jpg\"\n",
      "images\\harshil\\id.17.40.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.40.jpg\"\n",
      "images\\harshil\\id.17.41.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.41.jpg\"\n",
      "images\\harshil\\id.17.42.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.42.jpg\"\n",
      "images\\harshil\\id.17.43.jpg\n",
      "images\\harshil\\id.17.44.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.44.jpg\"\n",
      "images\\harshil\\id.17.45.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.45.jpg\"\n",
      "images\\harshil\\id.17.46.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.46.jpg\"\n",
      "images\\harshil\\id.17.47.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.47.jpg\"\n",
      "images\\harshil\\id.17.48.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.48.jpg\"\n",
      "images\\harshil\\id.17.49.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.49.jpg\"\n",
      "images\\harshil\\id.17.5.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.5.jpg\"\n",
      "images\\harshil\\id.17.50.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.50.jpg\"\n",
      "images\\harshil\\id.17.51.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.51.jpg\"\n",
      "images\\harshil\\id.17.52.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.52.jpg\"\n",
      "images\\harshil\\id.17.53.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.53.jpg\"\n",
      "images\\harshil\\id.17.54.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.54.jpg\"\n",
      "images\\harshil\\id.17.55.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.55.jpg\"\n",
      "images\\harshil\\id.17.56.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.56.jpg\"\n",
      "images\\harshil\\id.17.57.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.57.jpg\"\n",
      "images\\harshil\\id.17.58.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.58.jpg\"\n",
      "images\\harshil\\id.17.59.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.59.jpg\"\n",
      "images\\harshil\\id.17.6.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.6.jpg\"\n",
      "images\\harshil\\id.17.60.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.60.jpg\"\n",
      "images\\harshil\\id.17.61.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.61.jpg\"\n",
      "images\\harshil\\id.17.62.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.62.jpg\"\n",
      "images\\harshil\\id.17.63.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.63.jpg\"\n",
      "images\\harshil\\id.17.64.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.64.jpg\"\n",
      "images\\harshil\\id.17.65.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.65.jpg\"\n",
      "images\\harshil\\id.17.66.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.66.jpg\"\n",
      "images\\harshil\\id.17.67.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.67.jpg\"\n",
      "images\\harshil\\id.17.68.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.68.jpg\"\n",
      "images\\harshil\\id.17.69.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.69.jpg\"\n",
      "images\\harshil\\id.17.7.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.7.jpg\"\n",
      "images\\harshil\\id.17.70.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.70.jpg\"\n",
      "images\\harshil\\id.17.71.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.71.jpg\"\n",
      "images\\harshil\\id.17.72.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.72.jpg\"\n",
      "images\\harshil\\id.17.73.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.73.jpg\"\n",
      "images\\harshil\\id.17.74.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.74.jpg\"\n",
      "images\\harshil\\id.17.75.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.75.jpg\"\n",
      "images\\harshil\\id.17.76.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.76.jpg\"\n",
      "images\\harshil\\id.17.77.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.77.jpg\"\n",
      "images\\harshil\\id.17.78.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.78.jpg\"\n",
      "images\\harshil\\id.17.79.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.79.jpg\"\n",
      "images\\harshil\\id.17.8.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.8.jpg\"\n",
      "images\\harshil\\id.17.80.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.80.jpg\"\n",
      "images\\harshil\\id.17.81.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.81.jpg\"\n",
      "images\\harshil\\id.17.82.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.82.jpg\"\n",
      "images\\harshil\\id.17.83.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.83.jpg\"\n",
      "images\\harshil\\id.17.84.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.84.jpg\"\n",
      "images\\harshil\\id.17.85.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.85.jpg\"\n",
      "images\\harshil\\id.17.86.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.86.jpg\"\n",
      "images\\harshil\\id.17.87.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.87.jpg\"\n",
      "images\\harshil\\id.17.88.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.88.jpg\"\n",
      "images\\harshil\\id.17.89.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.89.jpg\"\n",
      "images\\harshil\\id.17.9.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.9.jpg\"\n",
      "images\\harshil\\id.17.90.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.90.jpg\"\n",
      "images\\harshil\\id.17.91.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.91.jpg\"\n",
      "images\\harshil\\id.17.92.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.92.jpg\"\n",
      "images\\harshil\\id.17.93.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.93.jpg\"\n",
      "images\\harshil\\id.17.94.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.94.jpg\"\n",
      "images\\harshil\\id.17.95.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.95.jpg\"\n",
      "images\\harshil\\id.17.96.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.96.jpg\"\n",
      "images\\harshil\\id.17.97.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.97.jpg\"\n",
      "images\\harshil\\id.17.98.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.98.jpg\"\n",
      "images\\harshil\\id.17.99.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\harshil\\id.17.99.jpg\"\n",
      "aligned_images\\pankaj\n",
      "images\\pankaj\\id.30.0.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.0.jpg\"\n",
      "images\\pankaj\\id.30.1.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.1.jpg\"\n",
      "images\\pankaj\\id.30.10.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.10.jpg\"\n",
      "images\\pankaj\\id.30.11.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.11.jpg\"\n",
      "images\\pankaj\\id.30.12.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.12.jpg\"\n",
      "images\\pankaj\\id.30.13.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.13.jpg\"\n",
      "images\\pankaj\\id.30.14.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.14.jpg\"\n",
      "images\\pankaj\\id.30.15.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.15.jpg\"\n",
      "images\\pankaj\\id.30.16.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.16.jpg\"\n",
      "images\\pankaj\\id.30.17.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.17.jpg\"\n",
      "images\\pankaj\\id.30.18.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.18.jpg\"\n",
      "images\\pankaj\\id.30.19.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.19.jpg\"\n",
      "images\\pankaj\\id.30.2.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.2.jpg\"\n",
      "images\\pankaj\\id.30.20.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.20.jpg\"\n",
      "images\\pankaj\\id.30.21.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.21.jpg\"\n",
      "images\\pankaj\\id.30.22.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.22.jpg\"\n",
      "images\\pankaj\\id.30.23.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.23.jpg\"\n",
      "images\\pankaj\\id.30.24.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.24.jpg\"\n",
      "images\\pankaj\\id.30.25.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.25.jpg\"\n",
      "images\\pankaj\\id.30.26.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.26.jpg\"\n",
      "images\\pankaj\\id.30.27.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.27.jpg\"\n",
      "images\\pankaj\\id.30.28.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.28.jpg\"\n",
      "images\\pankaj\\id.30.29.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.29.jpg\"\n",
      "images\\pankaj\\id.30.3.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.3.jpg\"\n",
      "images\\pankaj\\id.30.30.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.30.jpg\"\n",
      "images\\pankaj\\id.30.31.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.31.jpg\"\n",
      "images\\pankaj\\id.30.32.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.32.jpg\"\n",
      "images\\pankaj\\id.30.33.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.33.jpg\"\n",
      "images\\pankaj\\id.30.34.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.34.jpg\"\n",
      "images\\pankaj\\id.30.35.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.35.jpg\"\n",
      "images\\pankaj\\id.30.36.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.36.jpg\"\n",
      "images\\pankaj\\id.30.37.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.37.jpg\"\n",
      "images\\pankaj\\id.30.38.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.38.jpg\"\n",
      "images\\pankaj\\id.30.39.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.39.jpg\"\n",
      "images\\pankaj\\id.30.4.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.4.jpg\"\n",
      "images\\pankaj\\id.30.40.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.40.jpg\"\n",
      "images\\pankaj\\id.30.41.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.41.jpg\"\n",
      "images\\pankaj\\id.30.42.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.42.jpg\"\n",
      "images\\pankaj\\id.30.43.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.43.jpg\"\n",
      "images\\pankaj\\id.30.44.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.44.jpg\"\n",
      "images\\pankaj\\id.30.45.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.45.jpg\"\n",
      "images\\pankaj\\id.30.46.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.46.jpg\"\n",
      "images\\pankaj\\id.30.47.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.47.jpg\"\n",
      "images\\pankaj\\id.30.48.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.48.jpg\"\n",
      "images\\pankaj\\id.30.49.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.49.jpg\"\n",
      "images\\pankaj\\id.30.5.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.5.jpg\"\n",
      "images\\pankaj\\id.30.50.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.50.jpg\"\n",
      "images\\pankaj\\id.30.51.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.51.jpg\"\n",
      "images\\pankaj\\id.30.52.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.52.jpg\"\n",
      "images\\pankaj\\id.30.53.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.53.jpg\"\n",
      "images\\pankaj\\id.30.54.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.54.jpg\"\n",
      "images\\pankaj\\id.30.55.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.55.jpg\"\n",
      "images\\pankaj\\id.30.56.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.56.jpg\"\n",
      "images\\pankaj\\id.30.57.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.57.jpg\"\n",
      "images\\pankaj\\id.30.58.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.58.jpg\"\n",
      "images\\pankaj\\id.30.59.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.59.jpg\"\n",
      "images\\pankaj\\id.30.6.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.6.jpg\"\n",
      "images\\pankaj\\id.30.60.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.60.jpg\"\n",
      "images\\pankaj\\id.30.61.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.61.jpg\"\n",
      "images\\pankaj\\id.30.62.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.62.jpg\"\n",
      "images\\pankaj\\id.30.63.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.63.jpg\"\n",
      "images\\pankaj\\id.30.64.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.64.jpg\"\n",
      "images\\pankaj\\id.30.65.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.65.jpg\"\n",
      "images\\pankaj\\id.30.66.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.66.jpg\"\n",
      "images\\pankaj\\id.30.67.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.67.jpg\"\n",
      "images\\pankaj\\id.30.68.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.68.jpg\"\n",
      "images\\pankaj\\id.30.69.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.69.jpg\"\n",
      "images\\pankaj\\id.30.7.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.7.jpg\"\n",
      "images\\pankaj\\id.30.70.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.70.jpg\"\n",
      "images\\pankaj\\id.30.71.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.71.jpg\"\n",
      "images\\pankaj\\id.30.72.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.72.jpg\"\n",
      "images\\pankaj\\id.30.73.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.73.jpg\"\n",
      "images\\pankaj\\id.30.74.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.74.jpg\"\n",
      "images\\pankaj\\id.30.8.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.8.jpg\"\n",
      "images\\pankaj\\id.30.9.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\pankaj\\id.30.9.jpg\"\n",
      "aligned_images\\rashmi\n",
      "images\\rashmi\\id.21.0.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.0.jpg\"\n",
      "images\\rashmi\\id.21.1.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.1.jpg\"\n",
      "images\\rashmi\\id.21.10.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.10.jpg\"\n",
      "images\\rashmi\\id.21.100.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.100.jpg\"\n",
      "images\\rashmi\\id.21.101.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.101.jpg\"\n",
      "images\\rashmi\\id.21.102.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.102.jpg\"\n",
      "images\\rashmi\\id.21.103.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.103.jpg\"\n",
      "images\\rashmi\\id.21.104.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.104.jpg\"\n",
      "images\\rashmi\\id.21.11.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.11.jpg\"\n",
      "images\\rashmi\\id.21.12.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.12.jpg\"\n",
      "images\\rashmi\\id.21.13.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.13.jpg\"\n",
      "images\\rashmi\\id.21.14.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.14.jpg\"\n",
      "images\\rashmi\\id.21.15.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.15.jpg\"\n",
      "images\\rashmi\\id.21.16.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.16.jpg\"\n",
      "images\\rashmi\\id.21.17.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.17.jpg\"\n",
      "images\\rashmi\\id.21.18.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.18.jpg\"\n",
      "images\\rashmi\\id.21.19.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.19.jpg\"\n",
      "images\\rashmi\\id.21.2.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.2.jpg\"\n",
      "images\\rashmi\\id.21.20.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.20.jpg\"\n",
      "images\\rashmi\\id.21.21.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.21.jpg\"\n",
      "images\\rashmi\\id.21.22.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.22.jpg\"\n",
      "images\\rashmi\\id.21.23.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.23.jpg\"\n",
      "images\\rashmi\\id.21.24.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.24.jpg\"\n",
      "images\\rashmi\\id.21.25.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.25.jpg\"\n",
      "images\\rashmi\\id.21.26.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.26.jpg\"\n",
      "images\\rashmi\\id.21.27.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.27.jpg\"\n",
      "images\\rashmi\\id.21.28.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.28.jpg\"\n",
      "images\\rashmi\\id.21.29.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.29.jpg\"\n",
      "images\\rashmi\\id.21.3.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.3.jpg\"\n",
      "images\\rashmi\\id.21.30.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.30.jpg\"\n",
      "images\\rashmi\\id.21.31.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.31.jpg\"\n",
      "images\\rashmi\\id.21.32.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.32.jpg\"\n",
      "images\\rashmi\\id.21.33.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.33.jpg\"\n",
      "images\\rashmi\\id.21.34.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.34.jpg\"\n",
      "images\\rashmi\\id.21.35.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.35.jpg\"\n",
      "images\\rashmi\\id.21.36.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.36.jpg\"\n",
      "images\\rashmi\\id.21.37.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.37.jpg\"\n",
      "images\\rashmi\\id.21.38.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.38.jpg\"\n",
      "images\\rashmi\\id.21.39.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.39.jpg\"\n",
      "images\\rashmi\\id.21.4.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.4.jpg\"\n",
      "images\\rashmi\\id.21.40.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.40.jpg\"\n",
      "images\\rashmi\\id.21.41.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.41.jpg\"\n",
      "images\\rashmi\\id.21.42.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.42.jpg\"\n",
      "images\\rashmi\\id.21.43.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.43.jpg\"\n",
      "images\\rashmi\\id.21.44.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.44.jpg\"\n",
      "images\\rashmi\\id.21.45.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.45.jpg\"\n",
      "images\\rashmi\\id.21.46.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.46.jpg\"\n",
      "images\\rashmi\\id.21.47.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.47.jpg\"\n",
      "images\\rashmi\\id.21.48.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.48.jpg\"\n",
      "images\\rashmi\\id.21.49.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.49.jpg\"\n",
      "images\\rashmi\\id.21.5.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.5.jpg\"\n",
      "images\\rashmi\\id.21.50.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.50.jpg\"\n",
      "images\\rashmi\\id.21.51.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.51.jpg\"\n",
      "images\\rashmi\\id.21.52.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.52.jpg\"\n",
      "images\\rashmi\\id.21.53.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.53.jpg\"\n",
      "images\\rashmi\\id.21.54.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.54.jpg\"\n",
      "images\\rashmi\\id.21.55.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.55.jpg\"\n",
      "images\\rashmi\\id.21.56.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.56.jpg\"\n",
      "images\\rashmi\\id.21.57.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.57.jpg\"\n",
      "images\\rashmi\\id.21.58.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.58.jpg\"\n",
      "images\\rashmi\\id.21.59.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.59.jpg\"\n",
      "images\\rashmi\\id.21.6.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.6.jpg\"\n",
      "images\\rashmi\\id.21.60.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.60.jpg\"\n",
      "images\\rashmi\\id.21.61.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.61.jpg\"\n",
      "images\\rashmi\\id.21.62.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.62.jpg\"\n",
      "images\\rashmi\\id.21.63.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.63.jpg\"\n",
      "images\\rashmi\\id.21.64.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.64.jpg\"\n",
      "images\\rashmi\\id.21.65.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.65.jpg\"\n",
      "images\\rashmi\\id.21.66.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.66.jpg\"\n",
      "images\\rashmi\\id.21.67.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.67.jpg\"\n",
      "images\\rashmi\\id.21.68.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.68.jpg\"\n",
      "images\\rashmi\\id.21.69.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.69.jpg\"\n",
      "images\\rashmi\\id.21.7.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.7.jpg\"\n",
      "images\\rashmi\\id.21.70.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.70.jpg\"\n",
      "images\\rashmi\\id.21.71.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.71.jpg\"\n",
      "images\\rashmi\\id.21.72.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.72.jpg\"\n",
      "images\\rashmi\\id.21.73.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.73.jpg\"\n",
      "images\\rashmi\\id.21.74.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.74.jpg\"\n",
      "images\\rashmi\\id.21.75.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.75.jpg\"\n",
      "images\\rashmi\\id.21.76.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.76.jpg\"\n",
      "images\\rashmi\\id.21.77.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.77.jpg\"\n",
      "images\\rashmi\\id.21.78.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.78.jpg\"\n",
      "images\\rashmi\\id.21.79.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.79.jpg\"\n",
      "images\\rashmi\\id.21.8.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.8.jpg\"\n",
      "images\\rashmi\\id.21.80.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.80.jpg\"\n",
      "images\\rashmi\\id.21.81.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.81.jpg\"\n",
      "images\\rashmi\\id.21.82.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.82.jpg\"\n",
      "images\\rashmi\\id.21.83.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.83.jpg\"\n",
      "images\\rashmi\\id.21.84.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.84.jpg\"\n",
      "images\\rashmi\\id.21.85.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.85.jpg\"\n",
      "images\\rashmi\\id.21.86.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.86.jpg\"\n",
      "images\\rashmi\\id.21.87.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.87.jpg\"\n",
      "images\\rashmi\\id.21.88.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.88.jpg\"\n",
      "images\\rashmi\\id.21.89.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.89.jpg\"\n",
      "images\\rashmi\\id.21.9.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.9.jpg\"\n",
      "images\\rashmi\\id.21.90.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.90.jpg\"\n",
      "images\\rashmi\\id.21.91.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.91.jpg\"\n",
      "images\\rashmi\\id.21.92.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.92.jpg\"\n",
      "images\\rashmi\\id.21.93.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.93.jpg\"\n",
      "images\\rashmi\\id.21.94.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.94.jpg\"\n",
      "images\\rashmi\\id.21.95.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.95.jpg\"\n",
      "images\\rashmi\\id.21.96.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.96.jpg\"\n",
      "images\\rashmi\\id.21.97.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.97.jpg\"\n",
      "images\\rashmi\\id.21.98.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n",
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.98.jpg\"\n",
      "images\\rashmi\\id.21.99.jpg\n",
      "read data dimension:  3\n",
      "after data dimension:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 19:39:14.890135 29284 deprecation.py:323] From <ipython-input-3-c909ca50f077>:376: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(0, 5)\n",
      "detected_face: 0\n",
      "Unable to align \"images\\rashmi\\id.21.99.jpg\"\n",
      "Total number of images: 287\n",
      "Number of successfully aligned images: 0\n",
      "Number of classes: 9\n",
      "Number of images: 14\n",
      "Loading feature extraction model\n",
      "Model filename: 20170511-185253/20170511-185253.pb\n",
      "Calculating features for images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:258: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'aligned_images\\\\deeksha goyal\\\\.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7af206f9015c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mend_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrof_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mpaths_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mimages_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase_train_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0memb_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c909ca50f077>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrof_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrof_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(name, flatten, mode)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'aligned_images\\\\deeksha goyal\\\\.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as pjoin\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import facenet\n",
    "#import detect_face\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from time import sleep\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "output_dir_path = 'aligned_images'\n",
    "output_dir = os.path.expanduser(output_dir_path)\n",
    "if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "datadir = 'images'\n",
    "dataset = get_dataset(datadir)\n",
    "#print(dataset)\n",
    "print('Creating networks and loading parameters')\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = create_mtcnn(sess, './d_npy')\n",
    "\n",
    "minsize = 20  # minimum size of face\n",
    "threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "factor = 0.709  # scale factor\n",
    "margin = 44\n",
    "image_size = 182\n",
    "\n",
    "# Add a random key to the filename to allow alignment using multiple processes\n",
    "random_key = np.random.randint(0, high=99999)\n",
    "bounding_boxes_filename = os.path.join(output_dir, 'bounding_boxes_%05d.txt' % random_key)\n",
    "print('Goodluck')\n",
    "\n",
    "with open(bounding_boxes_filename, \"w\") as text_file:\n",
    "    nrof_images_total = 0\n",
    "    nrof_successfully_aligned = 0\n",
    "    for cls in dataset:\n",
    "        #print(cls.image_path)\n",
    "        output_class_dir = os.path.join(output_dir, cls.name)\n",
    "        print(output_class_dir)\n",
    "        if not os.path.exists(output_class_dir):\n",
    "            os.makedirs(output_class_dir)\n",
    "            #print(output_class_dir)\n",
    "        #print(cls.image_paths)\n",
    "        for image_path in cls.image_paths:\n",
    "            #print('a')\n",
    "            nrof_images_total += 1\n",
    "            filename = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "            output_filename = os.path.join(output_class_dir, filename + '.jpg')\n",
    "            print(image_path)\n",
    "            if not os.path.exists(output_filename):\n",
    "                try:\n",
    "                    img = misc.imread(image_path)\n",
    "                    print('read data dimension: ', img.ndim)\n",
    "                except (IOError, ValueError, IndexError) as e:\n",
    "                    errorMessage = '{}: {}'.format(image_path, e)\n",
    "                    print(errorMessage)\n",
    "                else:\n",
    "                    if img.ndim < 2:\n",
    "                        print('Unable to align \"%s\"' % image_path)\n",
    "                        text_file.write('%s\\n' % (output_filename))\n",
    "                        continue\n",
    "                    if img.ndim == 2:\n",
    "                        img = to_rgb(img)\n",
    "                        print('to_rgb data dimension: ', img.ndim)\n",
    "                    img = img[:, :, 0:3]\n",
    "                    print('after data dimension: ', img.ndim)\n",
    "\n",
    "                    bounding_boxes, _ = detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "                    nrof_faces = bounding_boxes.shape[0]\n",
    "                    print('shape='+str(bounding_boxes.shape))\n",
    "                    print('detected_face: %d' % nrof_faces)\n",
    "                    if nrof_faces > 0:\n",
    "                        det = bounding_boxes[:, 0:4]\n",
    "                        img_size = np.asarray(img.shape)[0:2]\n",
    "                        if nrof_faces > 1:\n",
    "                            bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\n",
    "                            img_center = img_size / 2\n",
    "                            offsets = np.vstack([(det[:, 0] + det[:, 2]) / 2 - img_center[1],\n",
    "                                                 (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\n",
    "                            offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n",
    "                            index = np.argmax(bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\n",
    "                            det = det[index, :]\n",
    "                        det = np.squeeze(det)\n",
    "                        bb_temp = np.zeros(4, dtype=np.int32)\n",
    "\n",
    "                        bb_temp[0] = det[0]\n",
    "                        bb_temp[1] = det[1]\n",
    "                        bb_temp[2] = det[2]\n",
    "                        bb_temp[3] = det[3]\n",
    "                        try:\n",
    "                            cropped_temp = img[bb_temp[1]:bb_temp[3], bb_temp[0]:bb_temp[2], :]\n",
    "                            scaled_temp = misc.imresize(cropped_temp, (image_size, image_size), interp='bilinear')\n",
    "                            nrof_successfully_aligned += 1\n",
    "                            misc.imsave(output_filename, scaled_temp)\n",
    "                            text_file.write('%s %d %d %d %d\\n' % (output_filename, bb_temp[0], bb_temp[1], bb_temp[2], bb_temp[3]))\n",
    "                        except Exception as e:\n",
    "                            os.remove(image_path)\n",
    "                    else:\n",
    "                        print('Unable to align \"%s\"' % image_path)\n",
    "                        text_file.write('%s\\n' % (output_filename))\n",
    "\n",
    "print('Total number of images: %d' % nrof_images_total)\n",
    "print('Number of successfully aligned images: %d' % nrof_successfully_aligned)\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        datadir = 'aligned_images'\n",
    "        dataset = get_dataset(datadir)\n",
    "        paths, labels = get_image_paths_and_labels(dataset)\n",
    "        print('Number of classes: %d' % len(dataset))\n",
    "        print('Number of images: %d' % len(paths))\n",
    "\n",
    "        print('Loading feature extraction model')\n",
    "        modeldir = '20170511-185253/20170511-185253.pb'\n",
    "        load_model(modeldir)\n",
    "\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "        # Run forward pass to calculate embeddings\n",
    "        print('Calculating features for images')\n",
    "        batch_size = 1000\n",
    "        image_size = 160\n",
    "        nrof_images = len(paths)\n",
    "        nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "        emb_array = np.zeros((nrof_images, embedding_size))\n",
    "        for i in range(nrof_batches_per_epoch):\n",
    "            start_index = i * batch_size\n",
    "            end_index = min((i + 1) * batch_size, nrof_images)\n",
    "            paths_batch = paths[start_index:end_index]\n",
    "            images = load_data(paths_batch, False, False, image_size)\n",
    "            feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "            emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "        classifier_filename = 'classifier'\n",
    "        classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "\n",
    "        # Train classifier\n",
    "        print('Training classifier')\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(emb_array, labels)\n",
    "\n",
    "        # Create a list of class names\n",
    "        class_names = [cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "        # Saving classifier model\n",
    "        with open(classifier_filename_exp, 'wb') as outfile:\n",
    "            pickle.dump((model, class_names), outfile)\n",
    "        print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "        print('Goodluck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
